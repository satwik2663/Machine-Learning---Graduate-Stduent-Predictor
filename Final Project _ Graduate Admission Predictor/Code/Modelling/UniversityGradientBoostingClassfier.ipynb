{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../data/all_records_northeastern.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the column, Unnamed as it is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_score</th>\n",
       "      <th>gre_score_quant</th>\n",
       "      <th>gre_score_verbal</th>\n",
       "      <th>test_score_toefl</th>\n",
       "      <th>undergraduation_score</th>\n",
       "      <th>work_ex</th>\n",
       "      <th>papers_published</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gre_score  gre_score_quant  gre_score_verbal  test_score_toefl  \\\n",
       "0        316              164               152              99.0   \n",
       "1        316              164               152              99.0   \n",
       "2        316              160               156             114.0   \n",
       "\n",
       "   undergraduation_score  work_ex  papers_published  status  \n",
       "0                   3.12       12                 0  reject  \n",
       "1                   3.12       12                 0  reject  \n",
       "2                   2.97        0                 0  reject  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of accept and reject in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept     574\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from above stats, our data is baised so we need to resample the data, in order to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_data=resample(dataset[dataset.status=='accept'],replace=True,n_samples=1000,random_state=123)\n",
    "balanced_data=balanced_data.append(dataset[dataset.status=='reject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept    1000\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset=balanced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the label and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encoded_dataset[['gre_score_quant','gre_score_verbal','test_score_toefl','undergraduation_score','work_ex','papers_published']].copy()\n",
    "Y=encoded_dataset[['status']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeltraining(model,X_train,X_test,Y_train,Y_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    \n",
    "    X_test = sc.transform(X_test)\n",
    "    print(X_test)\n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted_labels_test=model.predict(X_test)\n",
    "    predicted_labels_train=model.predict(X_train)\n",
    "    accuracy_test=accuracy_score(Y_test,predicted_labels_test)\n",
    "    accuracy_train=accuracy_score(Y_train,predicted_labels_train)\n",
    "    \n",
    "    \n",
    "    return model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1189225   0.73491402  0.39076816 -0.36262002 -0.62058721  1.89123818]\n",
      " [ 0.78723151 -0.2849141   0.43531487  0.59052431  0.41333471  1.89123818]\n",
      " [ 0.10761601 -0.48887972  0.12348788 -0.03768445  0.2308779  -0.59699686]\n",
      " ...\n",
      " [ 1.24030852  1.5507765   0.70259515  0.87213514 -1.04631976 -0.59699686]\n",
      " [ 1.01377002  1.5507765  -4.37573011 -2.09560971  1.14316194 -0.59699686]\n",
      " [ 0.33415451  2.16267337  0.5244083  -0.01602208  0.83906726 -0.59699686]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=GradientBoostingClassifier()\n",
    "model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc=modeltraining(model,X_train,X_test,Y_train,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7956730769230769\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8051713770294648\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[177  22]\n",
      " [ 63 154]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,predicted_labels_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.74      0.89      0.81       199\n",
      "      reject       0.88      0.71      0.78       217\n",
      "\n",
      "   micro avg       0.80      0.80      0.80       416\n",
      "   macro avg       0.81      0.80      0.80       416\n",
      "weighted avg       0.81      0.80      0.79       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predicted_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.75      0.90      0.82       801\n",
      "      reject       0.89      0.72      0.79       862\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      1663\n",
      "   macro avg       0.82      0.81      0.80      1663\n",
      "weighted avg       0.82      0.81      0.80      1663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train,predicted_labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning the parameters using grid search, tune the learning rate, min_samples_split, min_samples_leaf,max_depth etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1189225   0.73491402  0.39076816 -0.36262002 -0.62058721  1.89123818]\n",
      " [ 0.78723151 -0.2849141   0.43531487  0.59052431  0.41333471  1.89123818]\n",
      " [ 0.10761601 -0.48887972  0.12348788 -0.03768445  0.2308779  -0.59699686]\n",
      " ...\n",
      " [ 1.24030852  1.5507765   0.70259515  0.87213514 -1.04631976 -0.59699686]\n",
      " [ 1.01377002  1.5507765  -4.37573011 -2.09560971  1.14316194 -0.59699686]\n",
      " [ 0.33415451  2.16267337  0.5244083  -0.01602208  0.83906726 -0.59699686]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    " \n",
    "param_test1 = {'n_estimators':range(20,81,10)}\n",
    "gsearch1 = GridSearchCV(estimator = GradientBoostingClassifier(learning_rate=0.1, min_samples_split=2,min_samples_leaf=1,max_depth=8,max_features='sqrt',subsample=0.8,random_state=10), \n",
    "param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "\n",
    "# run grid search\n",
    "# grid_search = GridSearchCV(model, param_grid, cv=5,return_train_score=True)\n",
    "model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc=modeltraining(gsearch1,X_train,X_test,Y_train,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model after the grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=8,\n",
       "              max_features='sqrt', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sam...      subsample=0.8, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=False, n_jobs=4,\n",
       "       param_grid={'n_estimators': range(20, 81, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84375"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of train after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9993986770895971"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8953011290483509"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 80}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsearch1.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the pickle file of model and scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the trained decision tree classifier with Pickle\n",
    "gb_classifier_pkl_filename = r'..\\..\\model\\university_gradientboostingclassifier.pickel'\n",
    "gb_standard_scaler_filename = r'..\\..\\model\\UniversitystandardScaler_GBC_model.pickel'\n",
    "\n",
    "gradient_boosting_classifier_model_pkl = open(gb_classifier_pkl_filename, 'wb')\n",
    "pickle.dump(model,gradient_boosting_classifier_model_pkl)\n",
    "\n",
    "gradient_boosting_classifier_model_pkl.close()\n",
    "\n",
    "gb_standard_scaler_filename = open(gb_standard_scaler_filename, 'wb')\n",
    "pickle.dump(sc, gb_standard_scaler_filename)\n",
    "\n",
    "sc_rf_classifier_scaler_pkl.close()\n",
    "\n",
    "random_forest_classifier_model_pkl = open(rf_classifier_pkl_filename, 'rb')\n",
    "random_forest_classifier_model= pickle.load(random_forest_classifier_model_pkl)\n",
    "random_forest_classifier_model_pkl.close()\n",
    "\n",
    "sc_rf_classifier_scaler_pkl = open(standard_scaler_filename, 'rb')\n",
    "standard_scaler_rf_classifier= pickle.load(sc_rf_classifier_scaler_pkl)\n",
    "sc_rf_classifier_scaler_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Test Accuracy</th> \n",
    "    <th>Train Accuracy</th>\n",
    "    <th>Grid Search - Test Accuracy</th> \n",
    "    <th>Grid Search - Test Accuracy</th>\n",
    "    <th>Test F1 Score</th> \n",
    "    <th>Train F1 Score</th>\n",
    "    <th>Best Parameter</th>\n",
    "    <th>Interpretability</th>\n",
    "    <th>Reproducability</th>\n",
    "</tr>\n",
    "  <tr>\n",
    "    <th>Gradient Boosting Classifier</th>\n",
    "    <th>0.79</th>\n",
    "    <th>0.80</th>\n",
    "    <th>0.84</th>\n",
    "    <th>0.99</th>\n",
    "    <th>0.81</th>\n",
    "    <th>0.82</th>\n",
    "    <th>{'n_estimators': 80}</th>\n",
    "    <th>Yes</th>\n",
    "    <th>No</th>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
