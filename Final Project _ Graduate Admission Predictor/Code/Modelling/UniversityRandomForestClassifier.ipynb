{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../../data/all_records_northeastern.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the column, Unnamed as it is not necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(columns=['Unnamed: 0'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_score</th>\n",
       "      <th>gre_score_quant</th>\n",
       "      <th>gre_score_verbal</th>\n",
       "      <th>test_score_toefl</th>\n",
       "      <th>undergraduation_score</th>\n",
       "      <th>work_ex</th>\n",
       "      <th>papers_published</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316</td>\n",
       "      <td>164</td>\n",
       "      <td>152</td>\n",
       "      <td>99.0</td>\n",
       "      <td>3.12</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>114.0</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>317</td>\n",
       "      <td>168</td>\n",
       "      <td>149</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>317</td>\n",
       "      <td>161</td>\n",
       "      <td>156</td>\n",
       "      <td>106.0</td>\n",
       "      <td>2.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reject</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gre_score  gre_score_quant  gre_score_verbal  test_score_toefl  \\\n",
       "0        316              164               152              99.0   \n",
       "1        316              164               152              99.0   \n",
       "2        316              160               156             114.0   \n",
       "3        317              168               149             106.0   \n",
       "4        317              161               156             106.0   \n",
       "\n",
       "   undergraduation_score  work_ex  papers_published  status  \n",
       "0                   3.12       12                 0  reject  \n",
       "1                   3.12       12                 0  reject  \n",
       "2                   2.97        0                 0  reject  \n",
       "3                   2.83       15                 0  reject  \n",
       "4                   2.01        0                 0  reject  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count of accept and reject in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept     574\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.status.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from above stats, our data is baised so we need to resample the data, in order to balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_data=resample(dataset[dataset.status=='accept'],replace=True,n_samples=1000,random_state=123)\n",
    "balanced_data=balanced_data.append(dataset[dataset.status=='reject'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reject    1079\n",
       "accept    1000\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_data.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_dataset=balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_score</th>\n",
       "      <th>gre_score_quant</th>\n",
       "      <th>gre_score_verbal</th>\n",
       "      <th>test_score_toefl</th>\n",
       "      <th>undergraduation_score</th>\n",
       "      <th>work_ex</th>\n",
       "      <th>papers_published</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>314</td>\n",
       "      <td>165</td>\n",
       "      <td>149</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>315</td>\n",
       "      <td>162</td>\n",
       "      <td>153</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>309</td>\n",
       "      <td>163</td>\n",
       "      <td>146</td>\n",
       "      <td>104.0</td>\n",
       "      <td>2.64</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1401</th>\n",
       "      <td>310</td>\n",
       "      <td>162</td>\n",
       "      <td>148</td>\n",
       "      <td>99.0</td>\n",
       "      <td>2.85</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1177</th>\n",
       "      <td>320</td>\n",
       "      <td>170</td>\n",
       "      <td>150</td>\n",
       "      <td>104.0</td>\n",
       "      <td>3.86</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>accept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gre_score  gre_score_quant  gre_score_verbal  test_score_toefl  \\\n",
       "1589        314              165               149             100.0   \n",
       "1444        315              162               153             100.0   \n",
       "1461        309              163               146             104.0   \n",
       "1401        310              162               148              99.0   \n",
       "1177        320              170               150             104.0   \n",
       "\n",
       "      undergraduation_score  work_ex  papers_published  status  \n",
       "1589                   2.90        0                 2  accept  \n",
       "1444                   3.30       60                 0  accept  \n",
       "1461                   2.64       32                 0  accept  \n",
       "1401                   2.85       24                 0  accept  \n",
       "1177                   3.86        2                 1  accept  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining labels-X and Tragets-Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=encoded_dataset[['gre_score_quant','gre_score_verbal','test_score_toefl','undergraduation_score','work_ex','papers_published']].copy()\n",
    "Y=encoded_dataset[['status']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataset_encoded into training and testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2,random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def modeltraining(model,X_train,X_test,Y_train,Y_test):\n",
    "    sc = StandardScaler()\n",
    "    sc.fit(X_train)\n",
    "    X_train = sc.transform(X_train)\n",
    "    \n",
    "    X_test = sc.transform(X_test)\n",
    "    print(X_test)\n",
    "    model.fit(X_train,Y_train)\n",
    "    predicted_labels_test=model.predict(X_test)\n",
    "    predicted_labels_train=model.predict(X_train)\n",
    "    accuracy_test=accuracy_score(Y_test,predicted_labels_test)\n",
    "    accuracy_train=accuracy_score(Y_train,predicted_labels_train)\n",
    "    \n",
    "    \n",
    "    return model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling RandomForest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1189225   0.73491402  0.39076816 -0.36262002 -0.62058721  1.89123818]\n",
      " [ 0.78723151 -0.2849141   0.43531487  0.59052431  0.41333471  1.89123818]\n",
      " [ 0.10761601 -0.48887972  0.12348788 -0.03768445  0.2308779  -0.59699686]\n",
      " ...\n",
      " [ 1.24030852  1.5507765   0.70259515  0.87213514 -1.04631976 -0.59699686]\n",
      " [ 1.01377002  1.5507765  -4.37573011 -2.09560971  1.14316194 -0.59699686]\n",
      " [ 0.33415451  2.16267337  0.5244083  -0.01602208  0.83906726 -0.59699686]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lnuak\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model=RandomForestClassifier()\n",
    "model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc=modeltraining(model,X_train,X_test,Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8317307692307693"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9897775105231509"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.78      0.90      0.84       199\n",
      "      reject       0.89      0.77      0.83       217\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       416\n",
      "   macro avg       0.84      0.83      0.83       416\n",
      "weighted avg       0.84      0.83      0.83       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,predicted_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      accept       0.98      1.00      0.99       801\n",
      "      reject       1.00      0.98      0.99       862\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      1663\n",
      "   macro avg       0.99      0.99      0.99      1663\n",
      "weighted avg       0.99      0.99      0.99      1663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_train,predicted_labels_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypertuning the parameters using grid search, tune the max_depth and number of estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.1189225   0.73491402  0.39076816 -0.36262002 -0.62058721  1.89123818]\n",
      " [ 0.78723151 -0.2849141   0.43531487  0.59052431  0.41333471  1.89123818]\n",
      " [ 0.10761601 -0.48887972  0.12348788 -0.03768445  0.2308779  -0.59699686]\n",
      " ...\n",
      " [ 1.24030852  1.5507765   0.70259515  0.87213514 -1.04631976 -0.59699686]\n",
      " [ 1.01377002  1.5507765  -4.37573011 -2.09560971  1.14316194 -0.59699686]\n",
      " [ 0.33415451  2.16267337  0.5244083  -0.01602208  0.83906726 -0.59699686]]\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(X)\n",
    "\n",
    "\n",
    "param_grid = {\"n_estimators\": [10,15,20,30],\n",
    "              \"criterion\": ['gini'],\n",
    "             \"max_depth\": [10,15,20,25],\n",
    "             \"bootstrap\": [True],\n",
    "             \"min_samples_leaf\": [0.5,1,2]\n",
    "              \n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5,return_train_score=True)\n",
    "model,predicted_labels_test,predicted_labels_train,accuracy_test,accuracy_train,sc=modeltraining(grid_search,X_train,X_test,Y_train,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test data after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365384615384616"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9975947083583885"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=20, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 20,\n",
       " 'min_samples_leaf': 1,\n",
       " 'n_estimators': 30}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[182  17]\n",
      " [ 47 170]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test,predicted_labels_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the pickle file of model and scaler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump the trained decision tree classifier with Pickle\n",
    "rf_classifier_pkl_filename = r'..\\..\\model\\university_random_forest_predict.pickel'\n",
    "standard_scaler_filename = r'..\\..\\model\\UniversityRFstandardScaler_rf_model.pickel'\n",
    "\n",
    "random_forest_classifier_model_pkl = open(rf_classifier_pkl_filename, 'wb')\n",
    "pickle.dump(model, random_forest_classifier_model_pkl)\n",
    "\n",
    "random_forest_classifier_model_pkl.close()\n",
    "\n",
    "sc_rf_classifier_scaler_pkl = open(standard_scaler_filename, 'wb')\n",
    "pickle.dump(sc, sc_rf_classifier_scaler_pkl)\n",
    "\n",
    "sc_rf_classifier_scaler_pkl.close()\n",
    "\n",
    "random_forest_classifier_model_pkl = open(rf_classifier_pkl_filename, 'rb')\n",
    "random_forest_classifier_model= pickle.load(random_forest_classifier_model_pkl)\n",
    "random_forest_classifier_model_pkl.close()\n",
    "\n",
    "sc_rf_classifier_scaler_pkl = open(standard_scaler_filename, 'rb')\n",
    "standard_scaler_rf_classifier= pickle.load(sc_rf_classifier_scaler_pkl)\n",
    "sc_rf_classifier_scaler_pkl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Model</th>\n",
    "    <th>Test Accuracy</th> \n",
    "    <th>Train Accuracy</th>\n",
    "    <th>Grid Search - Test Accuracy</th> \n",
    "    <th>Grid Search - Test Accuracy</th>\n",
    "    <th>Test F1 Score</th> \n",
    "    <th>Train F1 Score</th>\n",
    "    <th>Best Parameter</th>\n",
    "    <th>Interpretability</th>\n",
    "    <th>Reproducability</th>\n",
    "</tr>\n",
    "  <tr>\n",
    "    <th>RandomForestClassifier</th>\n",
    "    <th>0.83</th>\n",
    "    <th>0.98</th>\n",
    "    <th>0.84</th>\n",
    "    <th>0.99</th>\n",
    "    <th>0.84</th>\n",
    "    <th>0.99</th>\n",
    "    <th>{'bootstrap': True,\n",
    " 'criterion': 'gini',\n",
    " 'max_depth': 20,\n",
    " 'min_samples_leaf': 1,\n",
    " 'n_estimators': 30}</th>\n",
    "    <th>Yes</th>\n",
    "    <th>No</th>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
